#!/usr/bin/env python

import argparse
import os
import sys
from datetime import datetime
import logging
import warnings

# third party imports
from h5py.h5py_warnings import H5pyDeprecationWarning
import openpyxl

from gmprocess.io.global_fetcher import fetch_data
from gmprocess.logging import setup_logger
from gmprocess.args import add_shared_args
from gmprocess.config import get_config
from gmprocess.event import get_event_dict, get_event_object
from gmprocess.io.read_directory import directory_to_streams
from gmprocess.streamcollection import StreamCollection
from gmprocess.stream import streams_to_dataframe
from gmprocess.processing import process_streams
from gmprocess.io.asdf.stream_workspace import StreamWorkspace
from gmprocess.config import get_config


CONFIG = get_config()
TIMEFMT = '%Y-%m-%dT%H:%M:%S'


def parse_eventinfo(arginfo):
    timestr, latstr, lonstr, depstr, magstr = arginfo
    etime = datetime.strptime(timestr, TIMEFMT)
    elat = float(latstr)
    elon = float(lonstr)
    edepth = float(depstr)
    emag = float(magstr)
    idstr = etime.strftime('%Y%m%d%H%M%S')

    edict = {'id': idstr,
             'time': etime,
             'lat': elat,
             'lon': elon,
             'depth': edepth,
             'magnitude': emag}
    return edict


def main(pparser, args):
    if not args.eventid and not args.eventinfo:
        print('Must specify either ComCat ID or event information')
        pparser.print_help()
        sys.exit(1)

    setup_logger(args)
    logging.info("Running datafetch.")

    rawdir = None
    if args.save_raw:
        rawdir = os.path.join(args.outdir, 'raw')

    if args.eventid:
        edict = get_event_dict(args.eventid)
        etime = edict['time'].datetime
    else:
        edict = parse_eventinfo(args.eventinfo)
        etime = edict['time']

    if args.directory:
        streams, bad, errors = directory_to_streams(args.directory)
        collection = StreamCollection(streams, drop_non_free=True)
    else:
        collection = fetch_data(etime,
                                edict['lat'],
                                edict['lon'],
                                edict['depth'],
                                edict['magnitude'],
                                rawdir=rawdir)
    if not len(collection):
        print('No data files found.')
        sys.exit(0)

    if not os.path.isdir(args.outdir):
        os.makedirs(args.outdir)

    if args.plot:
        plotdir = os.path.join(args.outdir, 'plots')
        config = get_config()
        idx = None
        for i, pstep in enumerate(config['processing']):
            if 'summary_plots' in pstep:
                idx = i
                break
        if idx is None:
            pstep = {'summary_plots': {'directory': plotdir}}
            config['processing'].append(pstep)
        else:
            pstep = config['processing'][idx]
            pstep['summary_plots']['directory'] = plotdir

        if 'build_report' in config:
            config['build_report']['run'] = True
            config['build_report']['directory'] = args.outdir
        else:
            config['build_report'] = {'run': True, 'directory': args.outdir}

    processed = process_streams(collection, edict, config=config)
    dataframe = streams_to_dataframe(processed, process=False)

    basename = edict['time'].strftime('%Y%m%d%H%M%S')
    if args.eventid:
        basename = args.eventid

    framename = os.path.join(args.outdir, basename + '_metrics.csv')
    workname = os.path.join(args.outdir, basename + '_workspace.hdf')
    if args.format == 'excel' or args.amptools_format:
        framename = os.path.join(args.outdir, basename + '_metrics.xlsx')

    # save the waveform data to an ASDF file.
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=H5pyDeprecationWarning)
        event = get_event_object(edict)
        if os.path.isfile(workname):
            os.remove(workname)
        workspace = StreamWorkspace(workname)
        workspace.addStreams(event, collection, label='raw')
        workspace.addStreams(event, processed, label='processed')
        provdata = workspace.getProvenance(edict['id'], labels=['processed'])
        provname = os.path.join(args.outdir, basename + '_provenance.csv')
        if args.format == 'excel':
            provname = os.path.join(args.outdir, basename + '_provenance.xlsx')

        workspace.close()

    # save dataframe to desired format
    if args.format == 'csv':
        if not args.amptools_format:
            dataframe.to_csv(framename, index=False)
        provdata.to_csv(provname, index=False)
    else:
        dataframe.to_excel(framename)
        if args.amptools_format:
            # we don't need the index column, so we'll delete it here
            wb = openpyxl.load_workbook(framename)
            ws = wb.active
            ws.delete_cols(1)
            ws.insert_rows(1)
            ws['A1'] = 'REFERENCE'
            ws['B1'] = dataframe['SOURCE'].iloc[0]
            wb.save(framename)
        provdata.to_excel(provname, index=False)

    print('Data from %i stations saved to %s' % (len(processed), args.outdir))
    print('Metrics: %s' % framename)
    print('Waveforms: %s' % workname)
    print('Provenance (processing history): %s' % provname)
    if args.plot:
        logging.info('%i plots saved to %s.' % (len(collection), plotdir))
    sys.exit(0)


if __name__ == '__main__':
    desc = """Fetch data from any available online data source.

    Creates in outdir:
        - ASDF file containing original (possibly raw) and processed waveforms.
        - CSV/Excel file containing configured stream metrics.
        - Provenance CSV/Excel file with processing history for each Trace.
        - (if --plot selected) plots directory with processed plots.
        - (if --save-raw selected) raw directory with raw data files.

    The ASDF file and CSV/Excel file will be named with ComCat ID if 
    specified, otherwise by event time.

    If --save-raw is specified, then original waveform files will be saved,
    otherwise these will be deleted after processing.

    If --amptools-format is specified, then the metrics file will be saved 
    to Excel format with an extra row at the top containing reference 
    information. If you are not a ShakeMap user, then you should probably 
    ignore this option.
    """
    parser = argparse.ArgumentParser(description=desc)

    # Required arguments
    parser.add_argument('outdir', help='Output file directory', type=str)

    # non-positional arguments
    parser.add_argument('-i', '--eventid', help='ComCat Event ID')
    parser.add_argument('-e', '--eventinfo', type=str, nargs=5,
                        metavar=('TIME', 'LAT', 'LON', 'DEPTH', 'MAG'),
                        help='Event information as TIME(YYYY-MM-DDTHH:MM:SS) LAT LON DEP MAG')
    parser.add_argument('-f', '--format',
                        help='Output format for metrics information',
                        choices=['excel', 'csv'], default='csv')
    parser.add_argument('-p', '--plot', action='store_true',
                        help='Make plots of processed waveforms')
    parser.add_argument('-r', '--save-raw', action='store_true',
                        help='Save raw data files in output directory')
    hstr = 'Save metrics spreadsheet in ShakeMap Amptools friendly format'
    parser.add_argument('-a', '--amptools-format', action='store_true',
                        help=hstr)
    hstr = 'Sidestep online data retrieval, read from local directory.'
    parser.add_argument('--directory',
                        help=hstr)
    # Shared arguments
    parser = add_shared_args(parser)

    pargs = parser.parse_args()
    main(parser, pargs)
