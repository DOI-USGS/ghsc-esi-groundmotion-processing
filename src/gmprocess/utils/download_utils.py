"""Module for download unility functions."""

# stdlib imports
import json
import logging
import warnings

# third party imports
import matplotlib.pyplot as plt
import numpy as np
import requests
from obspy.geodetics.base import locations2degrees
from obspy.taup import TauPyModel

# local imports
from gmprocess.io.global_fetcher import fetch_data
from gmprocess.utils.misc import get_rawdir

from gmprocess.utils import constants
from gmprocess.utils.strec import STREC

TIMEFMT2 = "%Y-%m-%dT%H:%M:%S.%f"


FLOAT_PATTERN = r"[-+]?[0-9]*\.?[0-9]+"

EVENT_TEMPLATE = (
    "https://earthquake.usgs.gov/earthquakes/feed/v1.0/detail/[EVENT].geojson"
)


def download_comcat_event(event_id):
    """Download event data from ComCat as GeoJSON.

    Args:
        event_id (str):
            ComCat event id.
    Returns:
        Dictionary with event information.
    """
    event_url = EVENT_TEMPLATE.replace("[EVENT]", event_id)
    response = requests.get(event_url)
    return response.json()


def download_event_data(event, event_dir, config, plot_raw=False):
    """Download event data, including rupture geometry, STREC results (if enabled),
    and waveforms.

    Args:
        event (ScalarEvent):
            Object containing basic event hypocenter, origin time, magnitude.
        event_dir (str):
            Path where raw directory should be created (if downloading).
        config (dict):
            Dictionary with gmprocess configuration information.
        plot_raw (bool):
            Plot raw waveforms after downloading.
    """
    # Make raw directory
    rawdir = get_rawdir(event_dir)

    download_rupture_file(event.id, event_dir)

    strec = None
    if config["strec"]["enabled"]:
        strec = get_strec_results(event, event_dir)

    tcollection, _ = fetch_data(
        event.time.datetime,
        event.latitude,
        event.longitude,
        event.depth_km,
        event.magnitude,
        config=config,
        rawdir=rawdir,
        stream_collection=False,
        strec=strec,
    )

    if len(tcollection):
        logging.debug("tcollection.describe_string():")
        logging.debug(tcollection.describe_string())

    if plot_raw:
        with warnings.catch_warnings():
            warnings.simplefilter("ignore", category=UserWarning)
            plot_raw_waveforms(rawdir, tcollection, event)


def plot_raw_waveforms(rawdir, tcollection, event):
    """Make PNG plots of a collection of raw waveforms.

    Args:
        rawdir (str):
            Directory where PNG files should be saved.
        tcollection (StreamCollection):
            Sequence of streams.
        event (ScalarEvent):
            Event object.

    """
    model = TauPyModel(model="iasp91")
    source_depth = event.depth_km
    if source_depth < 0:
        source_depth = 0
    eqlat = event.latitude
    eqlon = event.longitude
    for stream in tcollection:
        stlat = stream[0].stats.coordinates["latitude"]
        stlon = stream[0].stats.coordinates["longitude"]
        dist = float(locations2degrees(eqlat, eqlon, stlat, stlon))
        try:
            arrivals = model.get_travel_times(
                source_depth_in_km=source_depth,
                distance_in_degree=dist,
                phase_list=["P", "p", "Pn"],
            )
            arrival = arrivals[0]
            arrival_time = arrival.time
        except BaseException as e:
            fmt = 'Exception "%s" generated by get_travel_times() dist=%.3f depth=%.1f'
            logging.warning(fmt, str(e), dist, source_depth)
            arrival_time = 0.0
        ptime = arrival_time + (event.time - stream[0].stats.starttime)
        outfile = rawdir / f"{stream.get_id()}.png"

        fig, axeslist = plt.subplots(nrows=3, ncols=1, figsize=(12, 6))
        for ax, trace in zip(axeslist, stream):
            times = np.linspace(
                0.0, trace.stats.endtime - trace.stats.starttime, trace.stats.npts
            )
            ax.plot(times, trace.data, color="k")
            ax.set_xlabel("Seconds since start of trace")
            ax.axvline(ptime, color="r")
            ax.set_xlim(left=0, right=times[-1])
            legstr = "%s.%s.%s.%s" % (
                trace.stats.network,
                trace.stats.station,
                trace.stats.location,
                trace.stats.channel,
            )
            ax.legend(labels=[legstr], frameon=True, loc="upper left")
            tbefore = event.time + arrival_time < trace.stats.starttime + 1.0
            tafter = event.time + arrival_time > trace.stats.endtime - 1.0
            if tbefore or tafter:
                legstr = f"P arrival time {ptime:.1f} seconds"
                left, right = ax.get_xlim()
                xloc = left + (right - left) / 20
                bottom, top = ax.get_ylim()
                yloc = bottom + (top - bottom) / 10
                ax.text(xloc, yloc, legstr, color="r")
        plt.savefig(outfile, bbox_inches="tight")
        plt.close()


def download_rupture_file(event_id, event_dir):
    """Download rupture file from ComCat.

    Args:
        event_id (str):
            Event id.
        event_dir (pathlib.Path):
            Event directory.
    """
    try:
        data = download_comcat_event(event_id)
    except BaseException:
        logging.info(f"{event_id} not found in ComCat.")
        return
    try:
        shakemap_prod = data["properties"]["products"]["shakemap"][0]
        rupture_url = shakemap_prod["contents"]["download/rupture.json"]["url"]
        rupture_filename = event_dir / constants.RUPTURE_FILE
        response = requests.get(rupture_url)
        with open(rupture_filename, "wt", encoding="utf-8") as fout:
            json.dump(response.json(), fout)
    except BaseException:
        logging.info(f"{event_id} does not have a rupture.json file.")


def get_strec_results(event, event_dir):
    strec_file = event_dir / constants.STREC_FILE
    if strec_file.exists():
        strec = STREC.from_file(strec_file)
    else:
        strec = STREC.from_event(event)
        strec.to_file(strec_file)
    return strec
